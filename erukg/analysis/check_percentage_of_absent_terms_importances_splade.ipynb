{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "630749it [00:12, 50669.89it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_dataset = []\n",
    "with open(\"/scratch/lamdo/pyserini_experiments/scirepeval_collections/corpus/scirepeval_search_validation_evaluation.jsonl\") as f:\n",
    "    for line in tqdm(f):\n",
    "        line = json.loads(line)\n",
    "        title = line[\"title\"]\n",
    "        abstract = line[\"abstract\"]\n",
    "        doc_id = line[\"doc_id\"]\n",
    "\n",
    "        text = f\"{title}. {abstract}\"\n",
    "        text_not_lowered = f\"{title}\\n{abstract}\"\n",
    "        processed_line = {\n",
    "            \"doc_id\": doc_id,\n",
    "            \"text\": text,\n",
    "            \"text_not_lowered\": text_not_lowered,\n",
    "            \"present_keyphrases\": [],\n",
    "            \"absent_keyphrases\": []\n",
    "        }\n",
    "\n",
    "        processed_dataset.append(processed_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_representations = []\n",
    "with open(\"/scratch/lamdo/precompute_sparse_representations/custom_trained_combined_references_v8-1--scirepeval_search_validation_evaluation.jsonl\") as f:\n",
    "    for line in f:\n",
    "        jline = json.loads(line)\n",
    "        sparse_representations.append(jline)\n",
    "\n",
    "        if len(sparse_representations) == 20000: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [item[\"text\"] for item in processed_dataset[:20000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lamdo/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = [set(tokenizer.tokenize(item)) for item in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:00<00:00, 41719.86it/s]\n"
     ]
    }
   ],
   "source": [
    "percentages = []\n",
    "percentages_present = []\n",
    "for i in tqdm(range(len(tokenized_texts))):\n",
    "    total = len(sparse_representations[i])\n",
    "\n",
    "    num_absent = len([item for item in sparse_representations[i].keys() if item not in tokenized_texts[i]])\n",
    "    num_present = len([item for item in sparse_representations[i].keys() if item in tokenized_texts[i]])\n",
    "\n",
    "    percentages_present.append(num_present / len(tokenized_texts[i]))\n",
    "    percentages.append(num_absent / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.2501171758313665), np.float64(0.3348132341157254))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.mean(percentages), np.mean(percentages_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lexi': 1.64,\n",
       " 'core': 1.6,\n",
       " 'word': 1.55,\n",
       " 'links': 1.53,\n",
       " 'wa': 1.49,\n",
       " 'association': 1.45,\n",
       " 'semantic': 1.43,\n",
       " 'link': 1.25,\n",
       " 'responses': 1.17,\n",
       " 'associations': 1.12,\n",
       " 'or': 1.11,\n",
       " 'assessing': 1.05,\n",
       " 'coincidence': 1.03,\n",
       " 'response': 1.0,\n",
       " 'christian': 0.99,\n",
       " 'task': 0.91,\n",
       " 'tasks': 0.87,\n",
       " 'cue': 0.8,\n",
       " 'linking': 0.78,\n",
       " 'contrast': 0.69,\n",
       " 'nature': 0.67,\n",
       " 'item': 0.65,\n",
       " 'meaning': 0.59,\n",
       " 'concept': 0.56,\n",
       " 'ties': 0.46,\n",
       " 'importance': 0.43,\n",
       " 'sensory': 0.41,\n",
       " 'assessment': 0.39,\n",
       " '##ru': 0.36,\n",
       " 'defining': 0.34,\n",
       " 'language': 0.32,\n",
       " 'j': 0.31,\n",
       " 'reaction': 0.29,\n",
       " 'color': 0.27,\n",
       " 'linked': 0.25,\n",
       " 'object': 0.22,\n",
       " 'behavior': 0.22,\n",
       " 'reactions': 0.21,\n",
       " 'occurrence': 0.21,\n",
       " 'text': 0.17,\n",
       " 'relevance': 0.17,\n",
       " 'co': 0.13,\n",
       " 'assess': 0.11,\n",
       " 'norma': 0.07,\n",
       " 'latin': 0.02}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_representations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'##cal',\n",
       " '##eses',\n",
       " '##ing',\n",
       " '##ivation',\n",
       " '##ive',\n",
       " '##oth',\n",
       " '##ru',\n",
       " '##st',\n",
       " '##the',\n",
       " '##tive',\n",
       " '##yp',\n",
       " '%',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '.',\n",
       " '27',\n",
       " '5',\n",
       " '51',\n",
       " '62',\n",
       " '7',\n",
       " '72',\n",
       " '75',\n",
       " '86',\n",
       " ':',\n",
       " 'a',\n",
       " 'abstract',\n",
       " 'analyzed',\n",
       " 'appears',\n",
       " 'as',\n",
       " 'assessing',\n",
       " 'association',\n",
       " 'associations',\n",
       " 'authors',\n",
       " 'based',\n",
       " 'behind',\n",
       " 'by',\n",
       " 'co',\n",
       " 'coincidence',\n",
       " 'color',\n",
       " 'con',\n",
       " 'concept',\n",
       " 'connections',\n",
       " 'consider',\n",
       " 'contrast',\n",
       " 'core',\n",
       " 'cue',\n",
       " 'debate',\n",
       " 'defining',\n",
       " 'denoted',\n",
       " 'describing',\n",
       " 'driven',\n",
       " 'e',\n",
       " 'elements',\n",
       " 'emphasize',\n",
       " 'feature',\n",
       " 'features',\n",
       " 'followed',\n",
       " 'for',\n",
       " 'furthermore',\n",
       " 'g',\n",
       " 'given',\n",
       " 'h',\n",
       " 'had',\n",
       " 'high',\n",
       " 'importance',\n",
       " 'in',\n",
       " 'indicate',\n",
       " 'involve',\n",
       " 'item',\n",
       " 'its',\n",
       " 'lexi',\n",
       " 'links',\n",
       " 'matter',\n",
       " 'meaning',\n",
       " 'measure',\n",
       " 'medium',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'nature',\n",
       " 'norma',\n",
       " 'object',\n",
       " 'occurrences',\n",
       " 'of',\n",
       " 'or',\n",
       " 'others',\n",
       " 'paradigm',\n",
       " 'particularly',\n",
       " 'processes',\n",
       " 'properties',\n",
       " 'react',\n",
       " 'referred',\n",
       " 'relevance',\n",
       " 'relevant',\n",
       " 'remain',\n",
       " 'responses',\n",
       " 'results',\n",
       " 'role',\n",
       " 's',\n",
       " 'semantic',\n",
       " 'sensory',\n",
       " 'situation',\n",
       " 'some',\n",
       " 'such',\n",
       " 'suggest',\n",
       " 'tapped',\n",
       " 'task',\n",
       " 'tasks',\n",
       " 'terms',\n",
       " 'test',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'these',\n",
       " 'those',\n",
       " 'to',\n",
       " 'used',\n",
       " 'usually',\n",
       " 'values',\n",
       " 'wa',\n",
       " 'we',\n",
       " 'which',\n",
       " 'while',\n",
       " 'widely',\n",
       " 'with',\n",
       " 'word'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
