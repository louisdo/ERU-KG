{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "630749it [00:12, 48545.00it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_dataset = []\n",
    "with open(\"/scratch/lamdo/pyserini_experiments/scirepeval_collections/corpus/scirepeval_search_validation_evaluation.jsonl\") as f:\n",
    "    for line in tqdm(f):\n",
    "        line = json.loads(line)\n",
    "        title = line[\"title\"]\n",
    "        abstract = line[\"abstract\"]\n",
    "        doc_id = line[\"doc_id\"]\n",
    "\n",
    "        text = f\"{title}. {abstract}\"\n",
    "        text_not_lowered = f\"{title}\\n{abstract}\"\n",
    "        processed_line = {\n",
    "            \"doc_id\": doc_id,\n",
    "            \"text\": text,\n",
    "            \"text_not_lowered\": text_not_lowered,\n",
    "            \"present_keyphrases\": [],\n",
    "            \"absent_keyphrases\": []\n",
    "        }\n",
    "\n",
    "        processed_dataset.append(processed_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_representations = []\n",
    "with open(\"/scratch/lamdo/precompute_sparse_representations/custom_trained_combined_references_v8-1--scirepeval_search_validation_evaluation.jsonl\") as f:\n",
    "    for line in f:\n",
    "        jline = json.loads(line)\n",
    "        sparse_representations.append(jline)\n",
    "\n",
    "        if len(sparse_representations) == 20000: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [item[\"text\"] for item in processed_dataset[:20000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = [set(tokenizer.tokenize(item)) for item in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:00<00:00, 58583.71it/s]\n"
     ]
    }
   ],
   "source": [
    "percentages = []\n",
    "for i in tqdm(range(len(tokenized_texts))):\n",
    "    total = len(sparse_representations[i])\n",
    "\n",
    "    num_absent = len([item for item in sparse_representations[i].keys() if item not in tokenized_texts[i]])\n",
    "    percentages.append(num_absent / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2501171758313665"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.mean(percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
