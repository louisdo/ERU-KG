# @package config

lr: 2e-5
seed: 123
gradient_accumulation_steps: 1
weight_decay: 0.01
validation_metrics: [ MRR@10, recall@100, recall@200, recall@500 ]
pretrained_no_yamlconfig: false
nb_iterations: 150000 # 30000 for unarxive_intro_relatedwork_1citationpersentence
train_batch_size: 32  # number of gpus needs to divide this
eval_batch_size: 600
index_retrieve_batch_size: 500
record_frequency: 15000
train_monitoring_freq: 1000
warmup_steps: 20000
max_length: 256
fp16: false
augment_pairs: in_batch_negatives
matching_type: splade
monitoring_ckpt: loss  # or e.g. MRR@10
loss: InBatchPairwiseNLL
regularizer:
  FLOPS:
    lambda_q: 5e-4
    lambda_d: 3e-4
    T: 100000 # 30000 for unarxive_intro_relatedwork_1citationpersentence
    targeted_rep: rep
    reg: FLOPS